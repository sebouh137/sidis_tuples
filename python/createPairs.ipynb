{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "if (!(\"Notification\" in window)) {\n",
       "    alert(\"This browser does not support desktop notifications, so the %%notify magic will not work.\");\n",
       "} else if (Notification.permission !== 'granted' && Notification.permission !== 'denied') {\n",
       "    Notification.requestPermission(function (permission) {\n",
       "        if(!('permission' in Notification)) {\n",
       "            Notification.permission = permission;\n",
       "        }\n",
       "    })\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ROOT\n",
    "from ROOT import TFile\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import pandas as pd \n",
    "import time\n",
    "from os import listdir\n",
    "import uproot3\n",
    "import uproot\n",
    "%load_ext jupyternotify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class particle:\n",
    "    def __init__(self, pid, fourvector, virtual_photon,ThetaPQ ):## '__init__' is the constructor of the class\n",
    "        self.virtual_photon = virtual_photon\n",
    "        Nu = virtual_photon.E()   ##components of a 4-vector TLorentzVector\n",
    "        Q2 = -virtual_photon.M2() ## magnitud squared of a 4-vector TLorentzVector\n",
    "        self.proton = ROOT.TLorentzVector()  ## proton is an attribute of the class 'particle' just created.\n",
    "        self.proton.SetPxPyPzE(0,0,0, 0.938)  ## SetPxPyPzE is just a function of ROOT\n",
    "        self.W = (virtual_photon + self.proton).M() ##.M() return the magnitud of a TLorentzVector [W2=(p+q)2]\n",
    "        incoming_e = ROOT.TLorentzVector()\n",
    "        incoming_e.SetPxPyPzE(0,0,5.014,5.014)\n",
    "        part1 = virtual_photon.Vect().Cross(incoming_e.Vect()).Unit()\n",
    "        part2 = virtual_photon.Vect().Cross(fourvector.Vect()).Unit()\n",
    "        sign  = np.sign(part1.Dot(fourvector.Vect())) ## sign returns -1 0 or 1 if the input is negative, zero or positive.\n",
    "        self.PhiPQ = sign*np.arccos(part1.Dot(part2))\n",
    "        photon_pz = np.sqrt(Nu*Nu+Q2) #direction is positive by definition\n",
    "        self.bcm = photon_pz/(Nu + 0.938)#photon-nucleon center-of-mass velocity \n",
    "        self.ycm = 0.5*np.log(( 1+self.bcm)/(1-self.bcm)) #photon-nucleon center-of-mass rapidity\n",
    "        self.LorentzVector = fourvector #hadron four-vector. 4-vector is an input of this class\n",
    "        self.PhiLab = self.LorentzVector.Phi()\n",
    "        self.ThetaLab = self.LorentzVector.Theta()\n",
    "        self.E = self.LorentzVector.E() #energy in lab frame\n",
    "        self.vector = self.LorentzVector.Vect()\n",
    "        self.Pt = self.vector.Perp(virtual_photon.Vect().Unit()) #pT with respect to photon direction\n",
    "        self.Pl  = self.vector.Dot(virtual_photon.Vect().Unit()) #pL with respect to photon direction (in lab frame)\n",
    "        self.y =  0.5*np.log( (self.E+self.Pl)/(self.E-self.Pl)) #rapidity in lab frame\n",
    "        self.mT = np.sqrt(self.LorentzVector.M2() + self.Pt*self.Pt)\n",
    "        self.y_star = self.y - self.ycm\n",
    "        self.Pl_star = self.mT*np.sinh(self.y_star) # y is rapidity\n",
    "        self.Xf = 2.0*self.Pl_star/self.W \n",
    "        self.pid = pid\n",
    "        self.Zh = self.E/Nu\n",
    "        self.ThetaPQ = np.arctan(self.Pt/self.Pl)\n",
    "        self.P = np.sqrt(self.LorentzVector.Px()**2+self.LorentzVector.Py()**2+self.LorentzVector.Pz()**2)\n",
    "        #self.Nphe=Nphe\n",
    "        #self.deltaZ=deltaZ\n",
    "        #self.fidCut=fid\n",
    "        \n",
    "    def redefine(self, new_virtual_photon):\n",
    "        incoming_e = ROOT.TLorentzVector()\n",
    "        incoming_e.SetPxPyPzE(0,0,5.014,5.014)\n",
    "        part1 = new_virtual_photon.Vect().Cross(incoming_e.Vect()).Unit()\n",
    "        part2 = new_virtual_photon.Vect().Cross(self.LorentzVector.Vect()).Unit()\n",
    "        sign  = np.sign(part1.Dot(self.LorentzVector.Vect()))\n",
    "        self.PhiPQ = sign*np.arccos(part1.Dot(part2)) \n",
    "        self.Pt = self.LorentzVector.Vect().Perp(new_virtual_photon.Vect().Unit()) #pT with respect to photon direction\n",
    "        self.Pl  = self.LorentzVector.Vect().Dot(new_virtual_photon.Vect().Unit()) #pL with respect to photon direction (in lab frame)\n",
    "        self.y =  0.5*np.log( (self.E+self.Pl)/(self.E-self.Pl)) #rapidity in lab frame\n",
    "        self.ThetaPQ = np.arctan(self.Pt/self.Pl)\n",
    "        self.virtual_photon = new_virtual_photon\n",
    "        \n",
    "        return\n",
    "        \n",
    "    def print_properties(self):\n",
    "        print ('Hello, let me introduce myself, i am particle pid = ' , self.pid, ' with index ', self.index, ', from event  #', self.ievt, ' Nu and W', self.Nu, ' ' , self.W)\n",
    "        print ('zh = ', self.Zh, ' phi_pq= ', self.PhiPQ, ' theta_pq=' , self.ThetaPQ, 'E = ', self.E, ' xf', self.Xf,'Pt ', self.Pt, ' Pl= ', self.Pl, ' rapidity=' ,  self.y)\n",
    "        print ('pid = ' , self.pid)       \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataframes(filename, Target=1,maxevents=1e9,tree_name='ntuple_data',isMC=False):\n",
    "    dphi = np.array([])  \n",
    "    \n",
    "    ParticlesFromPrevious = []\n",
    "    \n",
    "    try:\n",
    "        myfile = TFile.Open('%s'%filename,'READ')\n",
    "        myfile.Print()\n",
    "    except:\n",
    "        print(\"could not open file\")\n",
    "    mytree = myfile.Get(tree_name)\n",
    "        \n",
    "    print (filename, ' has ', mytree.GetEntries(), ' entries')\n",
    "    \n",
    "    tupla = {}  \n",
    "    tupla['dphi'] = [] \n",
    "    tupla['dphi_lab'] = []\n",
    "    tupla['drap'] = []\n",
    "    tupla['h1_z'] = [] \n",
    "    tupla['h2_z'] = []\n",
    "    tupla['h1_cm_pt'] = []\n",
    "    tupla['h2_cm_pt'] = []\n",
    "    tupla['h1_xf'] = []\n",
    "    tupla['h2_xf'] = []\n",
    "    tupla['h1_rap'] = []\n",
    "    tupla['ycm'] = []\n",
    "    tupla['h2_rap'] = []\n",
    "    tupla['h1_pid'] = []\n",
    "    tupla['h2_pid'] = []\n",
    "    tupla['h1_cm_ph'] = []\n",
    "    tupla['h2_cm_ph'] = []\n",
    "    tupla['h1_cm_th'] = []  \n",
    "    tupla['h2_cm_th'] = []  \n",
    "    tupla['pair_mass'] = []\n",
    "    tupla['pair_pt'] = []\n",
    "    tupla['mx_eh1h2x'] = []\n",
    "    tupla['mx_eh1x'] = []\n",
    "    tupla['mx_eh2x'] = []\n",
    "    tupla['t']  = []\n",
    "    tupla['Q2'] = [] \n",
    "    tupla['nu'] = []\n",
    "    tupla['W']  = []\n",
    "    tupla['SampFracEl25'] = []\n",
    "    tupla['SampFracEl20'] = []\n",
    "    tupla['TargTypeSM'] = [] ## RD's vertex cuts\n",
    "    tupla['TargType'] = []   ## Taisiya's vertex cuts (nominal)\n",
    "    tupla['x'] = []\n",
    "    tupla['u']  = []\n",
    "    tupla['h1_ph'] = []\n",
    "    tupla['h1_th'] = []\n",
    "    tupla['h2_ph'] = []\n",
    "    tupla['h2_th'] = []\n",
    "    tupla['h1_deltaZ'] = []\n",
    "    tupla['h2_deltaZ'] = []\n",
    "    tupla['h1_Nphe'] = []\n",
    "    tupla['h2_Nphe'] = []\n",
    "    tupla['h1_Sector'] = []\n",
    "    tupla['h2_Sector'] = []\n",
    "    tupla['h1_FidCut'] = []\n",
    "    tupla['h2_FidCut'] = []\n",
    "    tupla['h1_Chi2CC'] = []\n",
    "    tupla['h2_Chi2CC'] = []\n",
    "    tupla['h1_StatCC'] = []\n",
    "    tupla['h2_StatCC'] = []\n",
    "    \n",
    "    \n",
    "    ## here we create another dictionary\n",
    "    tupla_mix = {}\n",
    "    tupla_mix['dphi'] = []\n",
    "    tupla_mix['dphi_lab'] = []\n",
    "    tupla_mix['drap'] = []\n",
    "    tupla_mix['h1_z'] = []\n",
    "    tupla_mix['h2_z'] = []\n",
    "    tupla_mix['h1_cm_pt'] = []\n",
    "    tupla_mix['h2_cm_pt'] = []\n",
    "    tupla_mix['h1_xf'] = []\n",
    "    tupla_mix['h2_xf'] = []\n",
    "    tupla_mix['h1_rap'] = []\n",
    "    tupla_mix['ycm'] = []\n",
    "    tupla_mix['h2_rap'] = []\n",
    "    tupla_mix['h1_pid'] = []\n",
    "    tupla_mix['h2_pid'] = []\n",
    "    tupla_mix['h1_cm_ph']   = []\n",
    "    tupla_mix['h2_cm_ph'] = []\n",
    "    tupla_mix['h1_cm_th'] = []\n",
    "    tupla_mix['h2_cm_th'] = []\n",
    "    tupla_mix['pair_mass'] = []\n",
    "    tupla_mix['pair_pt'] = []\n",
    "    tupla_mix['mx_eh1h2x'] = []\n",
    "    tupla_mix['mx_eh1x'] = []\n",
    "    tupla_mix['mx_eh2x'] = []\n",
    "    tupla_mix['t']  = []\n",
    "    tupla_mix['Q2'] = []\n",
    "    tupla_mix['nu'] = []\n",
    "    tupla_mix['W']  = []\n",
    "    tupla_mix['SampFracEl25'] = []\n",
    "    tupla_mix['SampFracEl20'] = []\n",
    "    tupla_mix['TargTypeSM'] = [] ## RD's vertex cuts\n",
    "    tupla_mix['TargType'] = []   ## Taisiya's vertex cuts (nominal)\n",
    "    tupla_mix['x'] = []\n",
    "    tupla_mix['u']  = []\n",
    "    tupla_mix['h1_ph'] = []\n",
    "    tupla_mix['h1_th'] = []\n",
    "    tupla_mix['h2_ph'] = []\n",
    "    tupla_mix['h2_th'] = []\n",
    "    tupla_mix['dphi_norot'] = [] #save variable before rotation to new virtual photon frame\n",
    "    tupla_mix['h2_cm_ph_norot'] = [] #save variable before rotation to new virtual photon frame\n",
    "    tupla_mix['h2_cm_th_norot'] = [] #save variable before rotation to new virtual photon frame\n",
    "    tupla_mix['h1_deltaZ'] = []\n",
    "    tupla_mix['h2_deltaZ'] = []\n",
    "    tupla_mix['h1_Nphe'] = []\n",
    "    tupla_mix['h2_Nphe'] = []\n",
    "    tupla_mix['h1_Sector'] = []\n",
    "    tupla_mix['h2_Sector'] = []\n",
    "    tupla_mix['h1_FidCut'] = []\n",
    "    tupla_mix['h2_FidCut'] = []    \n",
    "    tupla_mix['h1_Chi2CC'] = []\n",
    "    tupla_mix['h2_Chi2CC'] = []\n",
    "    tupla_mix['h1_StatCC'] = []\n",
    "    tupla_mix['h2_StatCC'] = []\n",
    "    \n",
    "    ## here we create another dictionary\n",
    "    tupla_trigger = {}\n",
    "    tupla_trigger['h1_pid'] = []\n",
    "    tupla_trigger['h1_xf'] = []\n",
    "    tupla_trigger['h1_xf_default'] = []\n",
    "    tupla_trigger['h1_z']  = []\n",
    "    tupla_trigger['h1_cm_pt'] = []\n",
    "    tupla_trigger['h1_rap']  = []\n",
    "    tupla_trigger['ycm'] = []\n",
    "    tupla_trigger['Q2'] = []\n",
    "    tupla_trigger['x'] = []\n",
    "    tupla_trigger['nu'] = []\n",
    "    tupla_trigger['W'] = []\n",
    "    tupla_trigger['SampFracEl25'] = []\n",
    "    tupla_trigger['SampFracEl20'] = []\n",
    "    tupla_trigger['TargTypeSM'] = [] ## RD's vertex cuts\n",
    "    tupla_trigger['TargType'] = []   ## Taisiya's vertex cuts (nominal)\n",
    "    tupla_trigger['h1_cm_ph'] = []\n",
    "    tupla_trigger['h1_cm_th'] = []\n",
    "    tupla_trigger['TargType'] = []\n",
    "    tupla_trigger['missing_mass'] = []\n",
    "    tupla_trigger['h1_ph'] = []\n",
    "    tupla_trigger['h1_th'] = []\n",
    "    tupla_trigger['h1_deltaZ'] = []\n",
    "    tupla_trigger['h1_Nphe'] = []\n",
    "    tupla_trigger['h1_Sector'] = []\n",
    "    tupla_trigger['h1_FidCut'] = []\n",
    "    tupla_trigger['h1_Chi2CC'] = []\n",
    "    tupla_trigger['h1_StatCC'] = []\n",
    "    \n",
    "    start = time.time()\n",
    "    print('About to loop over ', mytree.GetEntries() , ' entries')\n",
    "    for ievt  in range(mytree.GetEntries()):\n",
    "        #print('evnt: ',ievt, 'len ParticlesFromPrevious ', (len(ParticlesFromPrevious)))\n",
    "        \n",
    "        #for kkk  in range (len(ParticlesFromPrevious)):\n",
    "        #    print('evnt',ievt, 'ParticlesFromPrevious, pid:', ParticlesFromPrevious[kkk].pid, 'zh: ', \n",
    "                   #ParticlesFromPrevious[kkk].Zh, 'W: ',ParticlesFromPrevious[kkk].W )\n",
    "\n",
    "        mytree.GetEntry(ievt)   \n",
    "        if mytree.W<2.05 or mytree.Q2<1.0: continue\n",
    "        \n",
    "        # by default we apply the loose vertex cuts (Hayk's) The other cases remains as variables\n",
    "        if ievt>maxevents: break        \n",
    "        if(mytree.TargTypeHH==1):\n",
    "            TargType=1\n",
    "        elif(mytree.TargTypeHH==2):\n",
    "            TargType=2\n",
    "        else:\n",
    "            TargType=0\n",
    "        #print (TargType,  ' ' , Target)\n",
    "        if not(isMC) and (TargType!=Target): continue ## 'Target' is a argument of this function\n",
    "                \n",
    "        #print('PASO all cuts')\n",
    "        W = mytree.W\n",
    "        Nu = mytree.Nu\n",
    "        #get electron momentum:\n",
    "        Pe = np.sqrt(mytree.Pex*mytree.Pex + mytree.Pey*mytree.Pey+ mytree.Pez*mytree.Pez)\n",
    "        scattered_e = ROOT.TLorentzVector()\n",
    "        scattered_e.SetPxPyPzE(mytree.Pex, mytree.Pey, mytree.Pez, Pe)\n",
    "        incoming_e = ROOT.TLorentzVector()\n",
    "        incoming_e.SetPxPyPzE(0,0,5.014,5.014)\n",
    "        virtual_photon  = incoming_e - scattered_e \n",
    "        virtual_photon_unitvector = virtual_photon.Vect().Unit()\n",
    "        proton = ROOT.TLorentzVector()\n",
    "        proton.SetPxPyPzE(0,0,0, 0.938)\n",
    "        ## for each event the particles are saved in the 'particles' list.        \n",
    "        particles = []  ## this is how you define a list in python, this is created for each event\n",
    "        #print (' Entering main loop over particles')\n",
    "        for i in range(len(mytree.pid)):\n",
    "            #print(mytree.pid[i])\n",
    "            ## when the condition is true the 'continue' statement\n",
    "            ## takes me to the next iteration of the loop\n",
    "            if (abs(mytree.pid[i]) !=211 and mytree.pid[i]!=2212): continue \n",
    "                            \n",
    "            ## aplying the rest of cuts:\n",
    "            if ( mytree.P[i]<0.2 or mytree.ThetaLab[i]<10 or mytree.ThetaLab[i]>120 ):    continue\n",
    "            if ( mytree.pid[i]==-211 and (mytree.ThetaLab[i]>90 or mytree.ThetaLab[i]<25) ):    continue                \n",
    "            if ( mytree.pid[i]==-211 and mytree.ThetaLab[i]>40 and mytree.P[i]<0.2  ):    continue                \n",
    "            if ( mytree.pid[i]==-211 and mytree.ThetaLab[i]<40 and mytree.P[i]<0.5  ):    continue \n",
    "            if ( mytree.pid[i]==211  and mytree.P[i]>=3.0 and \n",
    "                (mytree.Nphe[i]<10 or mytree.Chi2CC[i]>0.0872 \n",
    "                 or mytree.StatCC[i]<=0 or mytree.NRowsCC[i]==0) ):    continue     \n",
    "  \n",
    "           \n",
    "            #print(mytree.pid[i])\n",
    "            i_lv = ROOT.TLorentzVector()    ## 4-vector of the hadron\n",
    "            i_lv.SetPxPyPzE(mytree.Px[i],mytree.Py[i],mytree.Pz[i],mytree.Zh[i]*Nu) \n",
    "            ## this is the 4-vector of the hadron\n",
    "            i_part = particle(mytree.pid[i], i_lv, virtual_photon, mytree.ThetaPQ[i] ) \n",
    "            ## particle is the class defined previously\n",
    "            ## in this 'particles' list there are NO cuts applied (except the pid and obvious ones)\n",
    "            particles.append(i_part)   ## save that particle in the 'particles' list\n",
    "            X = (virtual_photon + proton -  i_part.LorentzVector) #unobserved hadronic system\n",
    "            #print('event:',ievt,'particle i:', i,' with PID:',  i_part.pid, 'and Zh:',\n",
    "            #       i_part.Zh, ', W: ',i_part.W)\n",
    "            if i_part.Zh > 0.4: #only save triggers and do correlations if they have z>0.4\n",
    "            #if i_part.Pt>1.0: #only save triggers if pT>1.0 \n",
    "            ## HERE WE SAVE THE VARIABLES FOR THE TRIGGER PARTICLE (THE ONE WITH Zh>0.4)\n",
    "                tupla_trigger['h1_pid'].append(i_part.pid)\n",
    "                tupla_trigger['h1_xf'].append(i_part.Xf)\n",
    "                tupla_trigger['h1_xf_default'].append(-1)\n",
    "                tupla_trigger['h1_z'].append(i_part.Zh)\n",
    "                tupla_trigger['h1_cm_pt'].append(i_part.Pt)\n",
    "                tupla_trigger['h1_rap'].append(i_part.y_star)\n",
    "                tupla_trigger['ycm'].append(i_part.ycm)\n",
    "                tupla_trigger['h1_cm_ph'].append(i_part.PhiPQ)\n",
    "                tupla_trigger['h1_cm_th'].append(i_part.ThetaPQ)\n",
    "                tupla_trigger['missing_mass'].append(X.M())\n",
    "                tupla_trigger['Q2'].append(mytree.Q2)\n",
    "                tupla_trigger['x'].append(mytree.Xb)\n",
    "                tupla_trigger['nu'].append(mytree.Nu)\n",
    "                tupla_trigger['W'].append(mytree.W)\n",
    "                tupla_trigger['SampFracEl25'].append(mytree.SampFractionEl25)\n",
    "                tupla_trigger['SampFracEl20'].append(mytree.SampFractionEl20)\n",
    "                tupla_trigger['TargTypeSM'].append(mytree.TargTypeSM)  ## RD's vertex cuts\n",
    "                tupla_trigger['TargType'].append(mytree.TargType)    ## Taisiya's vertex cuts (nominal)\n",
    "                tupla_trigger['h1_ph'].append(mytree.PhiLab[i])\n",
    "                tupla_trigger['h1_th'].append(mytree.ThetaLab[i])#i_part.LorentzVector.Theta())\n",
    "                #print 'mytree.Pt[i] ' , mytree.Pt[i], ' check: ' ,i_part.Vector.Perp(virtual_photon_unitvector)\n",
    "                \n",
    "                #print('Testing theta PQ', mytree.ThetaPQ[i],  ' '  , 180.0*i_part.ThetaPQ/np.pi)\n",
    "                #print('Testing phi PQ', mytree.PhiPQ[i],  ' '  , 180.0*i_part.PhiPQ/np.pi),Nphe,deltaZ\n",
    "                tupla_trigger['h1_deltaZ'].append(mytree.deltaZ[i])\n",
    "                tupla_trigger['h1_Nphe'].append(mytree.Nphe[i])\n",
    "                tupla_trigger['h1_Sector'].append(mytree.Sector[i])\n",
    "                tupla_trigger['h1_FidCut'].append(mytree.FidCheckCutPiPlus[i])\n",
    "                tupla_trigger['h1_Chi2CC'].append(mytree.Chi2CC[i])\n",
    "                tupla_trigger['h1_StatCC'].append(mytree.StatCC[i])\n",
    "                \n",
    "                for j in range(len(mytree.pid)): \n",
    "                    if i==j: continue\n",
    "                    if (abs(mytree.pid[j]) !=211 and mytree.pid[j]!=2212): continue\n",
    "                    #print('evnt', ievt,' j:', j, ' , lenpid:',len(mytree.pid) )\n",
    "                    ## aplying the rest of cuts:\n",
    "                    if ( mytree.P[j]<0.2 or mytree.ThetaLab[j]<10 or mytree.ThetaLab[j]>120 ):    continue\n",
    "                    if ( mytree.pid[j]==-211 and (mytree.ThetaLab[j]>90 or mytree.ThetaLab[j]<25) ):    continue                \n",
    "                    if ( mytree.pid[j]==-211 and mytree.ThetaLab[j]>40 and mytree.P[j]<0.2  ):    continue                \n",
    "                    if ( mytree.pid[j]==-211 and mytree.ThetaLab[j]<40 and mytree.P[j]<0.5  ):    continue \n",
    "                    if ( mytree.pid[j]==211  and mytree.P[j]>=3.0 and \n",
    "                        (mytree.Nphe[j]<10 or mytree.Chi2CC[j]>0.0872 or mytree.StatCC[j]<=0 or \n",
    "                         mytree.NRowsCC[j]==0) ):    continue     \n",
    "                    #if (SampFractionEl==0):    continue\n",
    "                    #print('inside j loop')\n",
    "                    j_lv = ROOT.TLorentzVector()    \n",
    "                    j_lv.SetPxPyPzE(mytree.Px[j],mytree.Py[j],mytree.Pz[j],mytree.Zh[j]*Nu)\n",
    "                    j_part = particle(mytree.pid[j], j_lv, virtual_photon, mytree.ThetaPQ[j] )\n",
    "                    ## particle is the defined class\n",
    "\n",
    "                    \n",
    "                    ## TVector2.Phi_mpi_pi is a built in function of TVector2 class (2D vectors).\n",
    "                    ## Returns Phi angle in the interval [-pi,pi]. \n",
    "                    ## Also, we used the 'abs' to obtain the 0->pi range\n",
    "                    \n",
    "                    dphi = abs(ROOT.TVector2.Phi_mpi_pi(i_part.PhiPQ-j_part.PhiPQ))  \n",
    "                    dphi_lab = abs(ROOT.TVector2.Phi_mpi_pi(i_part.PhiLab-j_part.PhiLab))\n",
    "                    \n",
    "                    dy = i_part.y-j_part.y  ## i_part and j_part are object of the class particles \n",
    "                                            # and 'y' is a method, is the rapidity in the lab frame\n",
    "                    deta = dy\n",
    "                    ## Di-hadron 4-vector, is the sum P_{di-hadron} = P_{trigger-hadron} + P_{other-hadron}\n",
    "                    dipion = i_part.LorentzVector+j_part.LorentzVector  ## LorentzVector is a method of the \n",
    "                                    #particle class, is the '4-vector' of the particle, 3rd argument of the class\n",
    "                    \n",
    "                    X  = (virtual_photon + proton - dipion) #unobserved hadronic system\n",
    "                    X1 = (virtual_photon + proton - i_part.LorentzVector)\n",
    "                    X2 = (virtual_photon + proton - j_part.LorentzVector)\n",
    "\n",
    "                    tupla['dphi'].append(dphi)\n",
    "                    tupla['dphi_lab'].append(dphi_lab)\n",
    "                    tupla['drap'].append(dy)\n",
    "                    tupla['h1_z'].append(i_part.Zh)\n",
    "                    tupla['h2_z'].append(j_part.Zh)\n",
    "                    tupla['h1_cm_pt'].append(i_part.Pt)\n",
    "                    tupla['h2_cm_pt'].append(j_part.Pt)\n",
    "                    tupla['h1_xf'].append(i_part.Xf)\n",
    "                    tupla['h2_xf'].append(j_part.Xf)\n",
    "                    tupla['h1_rap'].append(i_part.y_star)\n",
    "                    tupla['ycm'].append(i_part.ycm)\n",
    "                    tupla['h2_rap'].append(j_part.y_star)\n",
    "                    tupla['h1_pid'].append(i_part.pid)\n",
    "                    tupla['h2_pid'].append(j_part.pid)\n",
    "                    tupla['h1_cm_ph'].append(i_part.PhiPQ)\n",
    "                    tupla['h2_cm_ph'].append(j_part.PhiPQ)\n",
    "                    tupla['h1_cm_th'].append(i_part.ThetaPQ)\n",
    "                    tupla['h2_cm_th'].append(j_part.ThetaPQ)\n",
    "                    tupla['pair_mass'].append(dipion.M())\n",
    "                    tupla['pair_pt'].append( dipion.Vect().Perp(virtual_photon_unitvector))\n",
    "                    tupla['mx_eh1h2x'].append(X.M())\n",
    "                    tupla['mx_eh1x'].append(X1.M())\n",
    "                    tupla['mx_eh2x'].append(X2.M())\n",
    "                    tupla['t'].append( -(virtual_photon- dipion).M2())\n",
    "                    tupla['Q2'].append(mytree.Q2)\n",
    "                    tupla['x'].append(mytree.Xb)\n",
    "                    tupla['nu'].append(mytree.Nu)\n",
    "                    tupla['W'].append(mytree.W)\n",
    "                    tupla['SampFracEl25'].append(mytree.SampFractionEl25)\n",
    "                    tupla['SampFracEl20'].append(mytree.SampFractionEl20)\n",
    "                    tupla['TargTypeSM'].append(mytree.TargTypeSM)  ## RD's vertex cuts\n",
    "                    tupla['TargType'].append(mytree.TargType)    ## Taisiya's vertex cuts (nominal)\n",
    "                    tupla['u'].append(-(scattered_e-proton).M2())\n",
    "                    tupla['h1_ph'].append(mytree.PhiLab[i])\n",
    "                    tupla['h1_th'].append(mytree.ThetaLab[i])\n",
    "                    tupla['h2_ph'].append(mytree.PhiLab[j])\n",
    "                    tupla['h2_th'].append(mytree.ThetaLab[j])\n",
    "                    tupla['h1_deltaZ'].append(mytree.deltaZ[i])\n",
    "                    tupla['h2_deltaZ'].append(mytree.deltaZ[j])\n",
    "                    tupla['h1_Nphe'].append(mytree.Nphe[i])\n",
    "                    tupla['h1_Sector'].append(mytree.Sector[i])\n",
    "                    tupla['h1_FidCut'].append(mytree.FidCheckCutPiPlus[i])\n",
    "                    tupla['h2_Nphe'].append(mytree.Nphe[j])\n",
    "                    tupla['h2_Sector'].append(mytree.Sector[j])\n",
    "                    tupla['h2_FidCut'].append(mytree.FidCheckCutPiPlus[j])                    \n",
    "                    tupla['h1_Chi2CC'].append(mytree.Chi2CC[i])\n",
    "                    tupla['h1_StatCC'].append(mytree.StatCC[i])\n",
    "                    tupla['h2_Chi2CC'].append(mytree.Chi2CC[j])\n",
    "                    tupla['h2_StatCC'].append(mytree.StatCC[j])\n",
    "                    \n",
    "         #end loop over secondary loop    \n",
    "                \n",
    "                ## here we are still under the condition of Zh>0.4\n",
    "                #print(ievt,i,j)\n",
    "                #print('')\n",
    "                for mixparticle in ParticlesFromPrevious: ## ParticlesFromPrevious is a list \n",
    "                                                          ## with 'particle' class objects\n",
    "                    #print('\\ninside mixparticle loop\\n')\n",
    "                    #print('i: ',i,'mixparticles pid:',mixparticle.pid,' zh :', mixparticle.Zh , ', W: ', \n",
    "                           #mixparticle.W, ' i_part Zh:', i_part.Zh, 'i_part.W: ',i_part.W)\n",
    "                    dphi = abs(ROOT.TVector2.Phi_mpi_pi(i_part.PhiPQ-mixparticle.PhiPQ))\n",
    "                    tupla_mix['dphi_norot'].append(dphi)\n",
    "                    tupla_mix['h2_cm_ph_norot'].append(mixparticle.PhiPQ)\n",
    "                    tupla_mix['h2_cm_th_norot'].append(mixparticle.ThetaPQ)\n",
    "\n",
    "                    mixparticle.redefine(virtual_photon) \n",
    "                    #recalculates variables in this' event photon frame (not in the previous one)\n",
    "                    #dphi = abs(ROOT.TVector2.Phi_mpi_pi(i_part.PhiPQ-mixparticle.PhiPQ))\n",
    "                    #print 'dphi_pq after redefinition: ', dphi , ' phi_pq ', mixparticle.PhiPQ\n",
    "                    \n",
    "                    dipion = i_part.LorentzVector+mixparticle.LorentzVector\n",
    "                    X  = (virtual_photon + proton - dipion)\n",
    "                    X1 = (virtual_photon + proton - i_part.LorentzVector)\n",
    "                    X2 = (virtual_photon + proton - mixparticle.LorentzVector)\n",
    "\n",
    "                    #recalculate the phi_pq. It has to be with respect to the photon direction\n",
    "                    \n",
    "                    dphi = abs(ROOT.TVector2.Phi_mpi_pi(i_part.PhiPQ-mixparticle.PhiPQ))\n",
    "                    dphi_lab = abs(ROOT.TVector2.Phi_mpi_pi(i_part.PhiLab-mixparticle.PhiLab))\n",
    "\n",
    "                    dy = i_part.y-mixparticle.y\n",
    "                    deta = dy#i_part.ThetaPQ-mixparticle.ThetaPQ\n",
    "                    tupla_mix['dphi'].append(dphi)\n",
    "                    tupla_mix['dphi_lab'].append(dphi_lab)\n",
    "                    tupla_mix['drap'].append(dy)\n",
    "                    tupla_mix['h1_z'].append(i_part.Zh)\n",
    "                    tupla_mix['h2_z'].append(mixparticle.Zh)\n",
    "                    tupla_mix['h1_cm_pt'].append(i_part.Pt)\n",
    "                    tupla_mix['h2_cm_pt'].append(mixparticle.Pt)\n",
    "                    tupla_mix['h1_xf'].append(i_part.Xf)\n",
    "                    tupla_mix['h2_xf'].append(mixparticle.Xf)\n",
    "                    tupla_mix['h1_rap'].append(i_part.y_star)\n",
    "                    tupla_mix['ycm'].append(i_part.ycm)\n",
    "                    tupla_mix['h2_rap'].append(mixparticle.y_star)\n",
    "                    tupla_mix['h1_pid'].append(i_part.pid)\n",
    "                    tupla_mix['h2_pid'].append(mixparticle.pid)\n",
    "                    tupla_mix['h1_cm_ph'].append(i_part.PhiPQ)\n",
    "                    tupla_mix['h2_cm_ph'].append(mixparticle.PhiPQ)\n",
    "                    tupla_mix['h1_cm_th'].append(i_part.ThetaPQ)\n",
    "                    tupla_mix['h2_cm_th'].append(mixparticle.ThetaPQ)\n",
    "                    tupla_mix['pair_mass'].append(dipion.M())\n",
    "                    tupla_mix['pair_pt'].append( dipion.Vect().Perp(virtual_photon_unitvector))\n",
    "                    tupla_mix['mx_eh1h2x'].append(X.M())\n",
    "                    tupla_mix['mx_eh1x'].append(X1.M())\n",
    "                    tupla_mix['mx_eh2x'].append(X2.M())\n",
    "                    tupla_mix['t'].append( -(virtual_photon- dipion).M2())\n",
    "                    tupla_mix['Q2'].append(mytree.Q2)\n",
    "                    tupla_mix['x'].append(mytree.Xb)\n",
    "                    tupla_mix['nu'].append(mytree.Nu)\n",
    "                    tupla_mix['W'].append(mytree.W)\n",
    "                    tupla_mix['SampFracEl25'].append(mytree.SampFractionEl25)\n",
    "                    tupla_mix['SampFracEl20'].append(mytree.SampFractionEl20)\n",
    "                    tupla_mix['TargTypeSM'].append(mytree.TargTypeSM)  ## RD's vertex cuts\n",
    "                    tupla_mix['TargType'].append(mytree.TargType)    ## Taisiya's vertex cuts (nominal)\n",
    "                    tupla_mix['u'].append(-(scattered_e-proton).M2())\n",
    "                    tupla_mix['h1_ph'].append(i_part.LorentzVector.Phi())\n",
    "                    tupla_mix['h1_th'].append(mytree.ThetaLab[i])\n",
    "                    tupla_mix['h2_ph'].append(mixparticle.LorentzVector.Phi())\n",
    "                    tupla_mix['h2_th'].append(mytree.ThetaLab[j])\n",
    "                    tupla_mix['h1_deltaZ'].append(mytree.deltaZ[i])\n",
    "                    tupla_mix['h2_deltaZ'].append(mytree.deltaZ[j])\n",
    "                    tupla_mix['h1_Nphe'].append(mytree.Nphe[i])\n",
    "                    tupla_mix['h1_Sector'].append(mytree.Sector[i])\n",
    "                    tupla_mix['h1_FidCut'].append(mytree.FidCheckCutPiPlus[i])\n",
    "                    tupla_mix['h2_Nphe'].append(mytree.Nphe[j])\n",
    "                    tupla_mix['h2_Sector'].append(mytree.Sector[j])\n",
    "                    tupla_mix['h2_FidCut'].append(mytree.FidCheckCutPiPlus[j])\n",
    "                    tupla_mix['h1_Chi2CC'].append(mytree.Chi2CC[i])\n",
    "                    tupla_mix['h1_StatCC'].append(mytree.StatCC[i])\n",
    "                    tupla_mix['h2_Chi2CC'].append(mytree.Chi2CC[j])\n",
    "                    tupla_mix['h2_StatCC'].append(mytree.StatCC[j])\n",
    "                    \n",
    "                    #for kk  in range (len(ParticlesFromPrevious)):\n",
    "                        #print('ParticlesFromPrevious, pid:', ParticlesFromPrevious[kk].pid, 'zh: ', \n",
    "                               #ParticlesFromPrevious[kk].Zh, 'W: ',ParticlesFromPrevious[kk].W )\n",
    "        #print (' Exiting main loop over particles (i loop, not over all entries)')\n",
    "        ParticlesFromPrevious = particles\n",
    "        #print ' going for next event'    \n",
    "        #print ' particles in event', len(particles\n",
    "        ##end loop over events correlations    \n",
    "    end = time.time()\n",
    "    print ('Processed in',  end-start, 'seconds')\n",
    "    ##printing the 3 tuples to the output file\n",
    "    df = pd.DataFrame(tupla)\n",
    "    df_mix= pd.DataFrame(tupla_mix)\n",
    "    df_trigger = pd.DataFrame(tupla_trigger)\n",
    "    print ('Number of triggers with z>0.4,  ', df.query('h1_z>0.4').shape[0])\n",
    "    print ('Number of pairs with z>0.4, '    , df_trigger.query('h1_z>0.4').shape[0]) \n",
    "    myfile.Close()\n",
    "    return df, df_mix, df_trigger        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## here we defined some dictionaries ({})\n",
    "df = {}\n",
    "df_mc = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n",
      "Wall time: 8.58 µs\n",
      "done with:  0  files\n",
      "/home/seba/di-hadron/data/P30/pb/Pb.root  has  26960616  entries\n",
      "About to loop over  26960616  entries\n",
      "Processed in 884.0687348842621 seconds\n",
      "Number of triggers with z>0.4,   48544\n",
      "Number of pairs with z>0.4,  296838\n",
      "/home/seba/di-hadron/data/P30/pb/Pb.root  has  26960616  entries\n",
      "About to loop over  26960616  entries\n",
      "Processed in 1882.7548670768738 seconds\n",
      "Number of triggers with z>0.4,   287161\n",
      "Number of pairs with z>0.4,  1425843\n",
      "end\n",
      "TFile: name=/home/seba/di-hadron/data/P30/pb/Pb.root, title=, option=READ\n",
      "TFile: name=/home/seba/di-hadron/data/P30/pb/Pb.root, title=, option=READ\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"5668f3dd-ea8f-416f-8ccb-a921a965a4ef\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"5668f3dd-ea8f-416f-8ccb-a921a965a4ef\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"Cell execution has finished!\"};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFile: name=/home/seba/di-hadron/data/P30/pb/Pb.root, title=, option=READ\n",
      "TFile: name=/home/seba/di-hadron/data/P30/pb/Pb.root, title=, option=READ\n"
     ]
    }
   ],
   "source": [
    "%%notify\n",
    "%time\n",
    "path = '/home/seba/di-hadron/data/P30/pb/'\n",
    "#path='/home/seba/'\n",
    "tar='Pb'\n",
    "Files = listdir(path) \n",
    "df['Pb'],df['Pb_mix'], df['Pb_trigger'] = [None,None,None]\n",
    "df['D_Pb'],df['D_Pb_mix'], df['D_Pb_trigger'] = [None,None,None]\n",
    "df['Fe'],df['Fe_mix'], df['Fe_trigger'] = [None,None,None]\n",
    "df['D_Fe'],df['D_Fe_mix'], df['D_Fe_trigger'] = [None,None,None]\n",
    "df['C'],df['C_mix'], df['C_trigger'] = [None,None,None]\n",
    "df['D_C'],df['D_C_mix'], df['D_C_trigger'] = [None,None,None]\n",
    "count=0\n",
    "for name in Files:\n",
    "    filename = path+name\n",
    "    print ('done with: ', count, ' files')\n",
    "    count=count+1\n",
    "    if( '.root' not in name): continue \n",
    "    pairs, pairs_mix, trigger = getDataframes(filename,Target=2) ## getDataframes is a function just created\n",
    "    df[tar] = pd.concat([ df[tar], pairs])\n",
    "    df['%s_mix'%tar] = pd.concat([ df['%s_mix'%tar], pairs_mix])\n",
    "    df['%s_trigger'%tar] = pd.concat([ df['%s_trigger'%tar], trigger])\n",
    "    pairs, pairs_mix, trigger = getDataframes(filename,Target=1) ## getDataframes is a function just created\n",
    "    df['D_%s'%tar] = pd.concat([ df['D_%s'%tar], pairs])\n",
    "    df['D_%s_mix'%tar] = pd.concat([ df['D_%s_mix'%tar], pairs_mix])\n",
    "    df['D_%s_trigger'%tar] = pd.concat([ df['D_%s_trigger'%tar], trigger])\n",
    "print('end')    \n",
    "#    print('Entries in the dataframe so far are ', df['D_Fe'].shape[0])\n",
    "#    print('Entries in the MIXED dataframe so far are ', df['D_Fe_mix'].shape[0])\n",
    "#    print('Entries in the trigger dataframe so far are ', df['D_Fe_trigger'].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## this is equivalent to: D_Fe->Draw(\"h1_ph>>h(100,0,1)\"), ok!\n",
    "plt.hist(df['D_Fe']['h1_ph'],bins=100,range=(0,1.0))\n",
    "df['D_Fe'].shape[0]  ## shape[0] return the number of rows of the array (number electrons)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['D_C'].query('h2_z>0.2').hist(figsize=(20,20),bins=100,\n",
    "#column=['dphi_lab','dphi','h1_ph','h2_ph','h1_cm_ph','h2_cm_ph'])\n",
    "#plt.savefig('plot_test.png', bbox_inches='tight')\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Pb'].query('h2_z>0.2').hist(figsize=(20,20),bins=100,\n",
    "                                      column=['h1_cm_pt','dphi_lab','dphi','h1_ph','h2_ph',\n",
    "                                              'h1_cm_ph','h2_cm_ph','h2_pid'])\n",
    "#plt.savefig('plot_test2.png', bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#def to_root(df,filename, treename):\n",
    "#    with uproot3.recreate(filename) as f:\n",
    "#        f[treename] = uproot3.newtree({col:df[col].dtype for col in df.columns})\n",
    "#        f[treename].extend(dict(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hadd Target file: P30_Pairs_Pb.root\n",
      "hadd compression setting for all output: 1\n",
      "hadd Source file 1: tmp_D_Pb.root\n",
      "hadd Source file 2: tmp_D_Pb_mix.root\n",
      "hadd Source file 3: tmp_D_Pb_trigger.root\n",
      "hadd Source file 4: tmp_Pb.root\n",
      "hadd Source file 5: tmp_Pb_mix.root\n",
      "hadd Source file 6: tmp_Pb_trigger.root\n",
      "hadd Target path: P30_Pairs_Pb.root:/\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"561e4b02-a067-4e2d-9ba2-212a2008439e\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"561e4b02-a067-4e2d-9ba2-212a2008439e\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"Cell execution has finished!\"};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%notify\n",
    "tar='Pb'\n",
    "outName='P30_Pairs_%s.root'%tar\n",
    "\n",
    "def to_root(df,filename, treename):\n",
    "    with uproot3.recreate(filename) as f:\n",
    "        f[treename] = uproot3.newtree({col:df[col].dtype for col in df.columns})\n",
    "        f[treename].extend(dict(df))\n",
    "\n",
    "to_root(df['%s'%tar]        ,'tmp_%s.root'%tar        ,'%s'%tar )\n",
    "to_root(df['%s_mix'%tar]    ,'tmp_%s_mix.root'%tar    ,'%s_mix'%tar )\n",
    "to_root(df['%s_trigger'%tar],'tmp_%s_trigger.root'%tar,'%s_trigger'%tar)\n",
    "#deuterium\n",
    "to_root(df['D_%s'%tar]        ,'tmp_D_%s.root'%tar        ,'D_%s'%tar )\n",
    "to_root(df['D_%s_mix'%tar]    ,'tmp_D_%s_mix.root'%tar    ,'D_%s_mix'%tar )\n",
    "to_root(df['D_%s_trigger'%tar],'tmp_D_%s_trigger.root'%tar,'D_%s_trigger'%tar)\n",
    "\n",
    "! hadd -f $outName tmp_*.root\n",
    "! rm tmp_*.root\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "outName='CC_Matching_Pairs'\n",
    "for target in ['Pb']:\n",
    "    to_root(df['%s'%target],'%s_%s.root'%(outName,target), key='%s'%target)\n",
    "    to_root(df['%s_mix'%target],'%s_%s.root'%(outName,target), key='%s_mix'%target,mode='a')\n",
    "    to_root(df['%s_trigger'%target],'%s_%s.root'%(outName,target), key='%s_trigger'%target, mode='a')\n",
    "    to_root(df['D_%s'%target],'%s_%s.root'%(outName,target), key='D_%s'%target,mode='a')\n",
    "    to_root(df['D_%s_mix'%target],'%s_%s.root'%(outName,target), key='D_%s_mix'%target,mode='a')\n",
    "    to_root(df['D_%s_trigger'%target],'%s_%s.root'%(outName,target), key='D_%s_trigger'%target, mode='a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path = '/home/seba/di-hadron/simul/Pb/'\n",
    "#path = '/home/seba/di-hadron/simul/'\n",
    "Files = listdir(path) \n",
    "df_mc['Pb'],df_mc['Pb_mix'], df_mc['Pb_trigger'] = [None,None,None]\n",
    "count =0\n",
    "for name in Files:\n",
    "    print('done with: ', count, ' files')\n",
    "    count=count+1\n",
    "    if( '.root' not in name): continue\n",
    "    \n",
    "    filename = path+name\n",
    "    print(filename)\n",
    "    pairs, pairs_mix, trigger = getDataframes(filename,tree_name='ntuple_sim',Target=1,isMC=True)\n",
    "    df_mc['Pb'] = pd.concat([ df_mc['Pb'], pairs])\n",
    "    df_mc['Pb_mix'] = pd.concat([ df_mc['Pb_mix'], pairs_mix])\n",
    "    df_mc['Pb_trigger'] = pd.concat([ df_mc['Pb_trigger'], trigger])\n",
    "\n",
    "    print('Entries in the dataframe so far are ', df_mc['Pb'].shape[0])\n",
    "    print('Entries in the MIXED dataframe so far are ', df_mc['Pb_mix'].shape[0])\n",
    "    print('Entries in the trigger dataframe so far are ', df_mc['Pb_trigger'].shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mc['D'].hist(figsize=(20,20),bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the MC file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for target in ['Pb']:\n",
    "    to_root(df_mc['%s'%target],'MC_Pairs_%s.root'%target, key='%s'%target)\n",
    "    to_root(df_mc['%s_mix'%target],'MC_Pairs_%s.root'%target, key='%s_mix'%target,mode='a')\n",
    "    to_root(df_mc['%s_trigger'%target],'MC_Pairs_%s.root'%target, key='%s_trigger'%target, mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for kk in range(5):\n",
    "    print('inside the loop',kk)\n",
    "print('outside the loop',kk)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    for ievt  in range(mytree.GetEntries()):\n",
    "        mytree.GetEntry(ievt)   \n",
    "        particles = []  ## this is how you define a list in python, this is created for each event\n",
    "        for i in range(len(mytree.pid)):\n",
    "            i_part = particle(mytree.pid[i], i_lv, virtual_photon, mytree.ThetaPQ[i], mytree.Nphe[i], mytree.deltaZ[i], mytree.FidCheckCutPiPlus[i])     \n",
    "            particles.append(i_part)\n",
    "            if i_part.Zh > 0.4: #only save triggers and do correlations if they have z>0.4\n",
    "                #tupla_trigger['h1_th'].append(mytree.ThetaLab[i])#i_part.LorentzVector.Theta())\n",
    "                #for j in range(len(mytree.pid)): \n",
    "                #    if i==j: continue\n",
    "                #    tupla['dphi'].append(dphi)\n",
    "                #print(ievt,i,j)\n",
    "                for mixparticle in ParticlesFromPrevious:\n",
    "                    print('inside mixparticle loop')\n",
    "                    #print(i,mixparticle, ParticlesFromPrevious)\n",
    "                    dphi = abs(ROOT.TVector2.Phi_mpi_pi(i_part.PhiPQ-mixparticle.PhiPQ))\n",
    "                    tupla_mix['dphi_norot'].append(dphi)\n",
    "\n",
    "                    mixparticle.redefine(virtual_photon) #recalculates variables in this' event photon frame (not in the previous one)\n",
    "                    tupla_mix['h2_th'].append(mytree.ThetaLab[j])\n",
    "        #print (' Exiting main loop over particles (i loop, not over all entries)')\n",
    "        ParticlesFromPrevious = particles\n",
    "        #print ' going for next event'    \n",
    "        #print ' particles in event', len(particles\n",
    "        ##end loop over events correlations    \n",
    "    end = time.time()\n",
    "    return df, df_mix, df_trigger        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
